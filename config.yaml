dataset:
  download_first: False #only download dataset files if true
  urls: 
    - jsb_chorales.pickle: "https://d2hg8soec8ck9v.cloudfront.net/datasets/polyphonic/jsb_chorales.pickle"
    - piano_midi.pickle: "https://d2hg8soec8ck9v.cloudfront.net/datasets/polyphonic/piano_midi.pickle"
    - muse_data.pickle: "https://d2hg8soec8ck9v.cloudfront.net/datasets/polyphonic/muse_data.pickle"
    - nottingham.pickle: "https://d2hg8soec8ck9v.cloudfront.net/datasets/polyphonic/nottingham.pickle"

  path: data/jsb_chorales.pickle #current dataset
  split: train

model:
  input_dim: 88
  hidden_dim: 600
  hidden_dim_em: 100 
  hidden_dim_tr: 200 
  latent_dim: 100
  combiner_type: 'dks'
  rnn_type: 'lstm'
  dropout: 0.0
  rnn_layers: 1

train:
  epochs: 300
  batch_size: 64
  num_workers: 5
  lr: 0.0008 #TODO: adjust this
  annealing_epochs: 20
  annealing: True
  save_model: True
  save_dir: train
  save_every: 20
  logger_name: lstm_600_new_annealing_sum_t_dropout #for logger
  experiment_dir: experiments
  proj_name: lstm_600_new_annealing_sum_t_dropout #for wandb
  wandb_user_name: farrinsofian #for wandb

test:
  ckpt_path: experiments/train_84796/best_model_20.pt
  batch_size: 64 
  save_dir: audio_samples
  split: train
  S: 3

sample:
  ckpt_path: experiments/train_84796/best_model_20.pt
  num_samples: 1
  sequence_length: 40
  exp_name: new_model #for each experiment
  threshhold: 0.3
  split: train # this is if you want to sample from the train or test set with no random z