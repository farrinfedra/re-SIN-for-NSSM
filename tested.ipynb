{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import midi_to_song, log_midis\n",
    "from loss import kl_normal, log_bernoulli_with_logits\n",
    "import logging\n",
    "import torch.nn.functional as F\n",
    "from dataloader import MusicDataset\n",
    "from model import DVAE \n",
    "from einops import repeat, rearrange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = OmegaConf.load('config.yaml')\n",
    "\n",
    "model = DVAE(input_dim=config.model.input_dim, \n",
    "                hidden_dim=config.model.hidden_dim,\n",
    "                hidden_dim_em=config.model.hidden_dim_em, \n",
    "                hidden_dim_tr=config.model.hidden_dim_tr, \n",
    "                latent_dim=config.model.latent_dim,\n",
    "                dropout=config.model.dropout,\n",
    "                combiner_type=config.model.combiner_type,\n",
    "                rnn_type=config.model.rnn_type).to(device)\n",
    "\n",
    "dataset = MusicDataset(config.dataset, split=config.sample.split)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=False)\n",
    "#load weights\n",
    "ckpt_path = config.test.ckpt_path\n",
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "a = 0\n",
    "b = 0\n",
    "c = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_lengths: tensor([129,  65])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with torch.no_grad():   \n",
    "    for j, (encodings, sequence_lengths) in enumerate(dataloader):\n",
    "        \n",
    "        print(f'sequence_lengths: {sequence_lengths}')\n",
    "        encodings = encodings.to(device)\n",
    "        sequence_lengths = sequence_lengths.to(device)\n",
    "        \n",
    "        x_hat, mus_inference, sigmas_inference, mus_generator, sigmas_generators = model(encodings)\n",
    "        \n",
    "        #get loss with only sum over latent dim dimension\n",
    "        reconstruction_loss = log_bernoulli_with_logits(encodings, x_hat, sequence_lengths, T_reduction='none') \n",
    "        kl_loss = kl_normal(mus_inference, \n",
    "                            sigmas_inference, \n",
    "                            mus_generator, \n",
    "                            sigmas_generators, \n",
    "                            sequence_lengths,\n",
    "                            T_reduction='none')\n",
    "        \n",
    "        kl_loss = kl_loss.mean(-1) #sum over T\n",
    "        reconstruction_loss = reconstruction_loss.mean(-1) #sum over T\n",
    "        \n",
    "        #for a: #importance sampling\n",
    "        z, mu_q, var_q = model.encoder(encodings)\n",
    "        bs = encodings.shape[0]\n",
    "        max_sequence_length = encodings.shape[1]\n",
    "        loss_s = torch.zeros(bs)\n",
    "        all_exponent_args = []\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_lengths.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction_loss: 10.08811092376709\n",
      "kl_loss: 1.011856198310852\n"
     ]
    }
   ],
   "source": [
    "reconstruction_loss = reconstruction_loss[0]\n",
    "kl_loss = kl_loss[0]\n",
    "\n",
    "print(f'reconstruction_loss: {reconstruction_loss}')\n",
    "print(f'kl_loss: {kl_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.1000)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nelbo_matrix = reconstruction_loss + kl_loss\n",
    "nelbo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2494.1921)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nelbo_matrix = nelbo_matrix.sum(-1) #sum over batch_size\n",
    "# nelbo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_lengths_sum = sequence_lengths[0]\n",
    "sequence_lengths_sum\n",
    "nelbo_b = nelbo_matrix / sequence_lengths_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0860)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nelbo_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for b:\n",
    "nelbo_matrix = reconstruction_loss + kl_loss\n",
    "nelbo_matrix = nelbo_matrix.sum(-1) #sum over batch_size\n",
    "sequence_lengths_sum = sequence_lengths.sum(-1)\n",
    "nelbo_b = nelbo_matrix / sequence_lengths_sum\n",
    "b += nelbo_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.8567)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
