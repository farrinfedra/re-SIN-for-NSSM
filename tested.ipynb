{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import midi_to_song, log_midis\n",
    "from loss import kl_normal, log_bernoulli_with_logits\n",
    "import logging\n",
    "import torch.nn.functional as F\n",
    "from dataloader import MusicDataset\n",
    "from model import DVAE \n",
    "from einops import repeat, rearrange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = OmegaConf.load('config.yaml')\n",
    "\n",
    "model = DVAE(input_dim=config.model.input_dim, \n",
    "                hidden_dim=config.model.hidden_dim,\n",
    "                hidden_dim_em=config.model.hidden_dim_em, \n",
    "                hidden_dim_tr=config.model.hidden_dim_tr, \n",
    "                latent_dim=config.model.latent_dim,\n",
    "                dropout=config.model.dropout,\n",
    "                combiner_type=config.model.combiner_type,\n",
    "                rnn_type=config.model.rnn_type).to(device)\n",
    "\n",
    "dataset = MusicDataset(config.dataset, split=config.sample.split)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=False)\n",
    "#load weights\n",
    "ckpt_path = config.test.ckpt_path\n",
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "a = 0\n",
    "b = 0\n",
    "c = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_lengths: tensor([129,  65])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with torch.no_grad():   \n",
    "    for j, (encodings, sequence_lengths) in enumerate(dataloader):\n",
    "        \n",
    "        print(f'sequence_lengths: {sequence_lengths}')\n",
    "        encodings = encodings.to(device)\n",
    "        sequence_lengths = sequence_lengths.to(device)\n",
    "        \n",
    "        x_hat, mus_inference, sigmas_inference, mus_generator, sigmas_generators = model(encodings)\n",
    "        \n",
    "        #get loss with only sum over latent dim dimension\n",
    "        reconstruction_loss = log_bernoulli_with_logits(encodings, x_hat, sequence_lengths, T_reduction='none') \n",
    "        kl_loss = kl_normal(mus_inference, \n",
    "                            sigmas_inference, \n",
    "                            mus_generator, \n",
    "                            sigmas_generators, \n",
    "                            sequence_lengths,\n",
    "                            T_reduction='none')\n",
    "        \n",
    "        kl_loss = kl_loss.sum(-1) #sum over T\n",
    "        reconstruction_loss = reconstruction_loss.sum(-1) #sum over T\n",
    "        \n",
    "        #for a: #importance sampling\n",
    "        z, mu_q, var_q = model.encoder(encodings)\n",
    "        bs = encodings.shape[0]\n",
    "        max_sequence_length = encodings.shape[1]\n",
    "        loss_s = torch.zeros(bs)\n",
    "        all_exponent_args = []\n",
    "        \n",
    "        for _ in range(config.test.S):\n",
    "            z_s = mu_q + torch.sqrt(var_q) * torch.randn_like(mu_q)\n",
    "            x_hat_s, mu_p, var_p = model.decoder(z_s)\n",
    "\n",
    "            range_tensor = repeat(torch.arange(max_sequence_length), 'l -> b l', b=bs).to(sequence_lengths.device) #shape: (batch, seq_len)\n",
    "            mask = range_tensor < rearrange(sequence_lengths, 'b -> b ()')\n",
    "            mask = mask.to(sequence_lengths.device)\n",
    "            mask = rearrange(mask, 'b s -> b s ()') #shape : (bs, seq_len, latent_dim)\n",
    "            \n",
    "            #binary cross entropy\n",
    "            log_s_recosntruction_loss = log_bernoulli_with_logits(encodings, x_hat_s, sequence_lengths, T_reduction='mean')\n",
    "            \n",
    "            #gaussian log prob p(z)\n",
    "            nll_p_z = F.gaussian_nll_loss(mu_p, z_s, var_p, reduction='none')\n",
    "            nll_p_z = nll_p_z * mask.float()\n",
    "            log_p_z = nll_p_z.sum(-1).mean(-1) #sum over latent dim and T #final shape (batch,)\n",
    "            \n",
    "            #gaussian log prob q(z|x)\n",
    "            nll_q_z = F.gaussian_nll_loss(mu_q, z_s, var_q, reduction='none')\n",
    "            nll_q_z = nll_q_z * mask.float()\n",
    "            log_q_z = nll_q_z.sum(-1).mean(-1) #sum over latent dim and T #final shape (batch,)\n",
    "            \n",
    "            # loss_s += torch.exp(-(log_s_recosntruction_loss + log_p_z - log_q_z))\n",
    "            exponent_arg = -(log_s_recosntruction_loss + log_p_z - log_q_z)\n",
    "            all_exponent_args.append(exponent_arg)\n",
    "                \n",
    "            \n",
    "        loss_s = -torch.logsumexp(torch.stack(all_exponent_args), dim=0) + torch.log(torch.tensor(config.test.S, dtype=torch.float))\n",
    "        loss_s = loss_s.mean()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-13.2727,  -9.4349]), tensor([-13.1605,  -9.4529])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_exponent_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.3294)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
